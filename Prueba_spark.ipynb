{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_JR5j4azzvp",
        "outputId": "e9bd7d91-8c3f-48b6-c3e3-37e6fead4b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "#Descargamos spark\n",
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "xAFbY32q0JoY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear sesión de Spark\n",
        "spark = SparkSession.builder.appName(\"DementiaModel\").getOrCreate()"
      ],
      "metadata": {
        "id": "ZxPa-u8t0ThM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargar y analizar la dataa\n",
        "df = pd.read_csv(\"data.csv\")"
      ],
      "metadata": {
        "id": "lhcwcobA0hC4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir DataFrame de pandas a DataFrame de Spark\n",
        "spark_df = spark.createDataFrame(df)"
      ],
      "metadata": {
        "id": "C0ZqL_wa0pLb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar los primeros registros\n",
        "spark_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D9Tg9UB0ssv",
        "outputId": "79e1177a-69a2-41fb-85ca-8d033f53e04a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+------+--------+------------+--------------+----+----+------+-----------+-----------+-------+----------------+----------------+---------------+-----------------+-----------+-----------+----------+------+----------------+-----------------+-------+---------+---------+\n",
            "| ID|age|gender|dementia|dementia_all|educationyears|  EF|  PS|Global|glucose_min|glucose_max|smoking|hypertension_sys|hypertension_dia|cholesterol_ldl|cholesterol_total|lacunes_num|fazekas_cat|     study|study1|SVD Simple Score|SVD Amended Score|Fazekas|lac_count|CMB_count|\n",
            "+---+---+------+--------+------------+--------------+----+----+------+-----------+-----------+-------+----------------+----------------+---------------+-----------------+-----------+-----------+----------+------+----------------+-----------------+-------+---------+---------+\n",
            "|  1| 80|     F|       0|           0|             8|0.98|0.67|  0.82|         82|        128|      1|             132|              75|            174|              221|          2|       mild|BEBACOHORT|group1|               1|                0|      0|        0|        0|\n",
            "|  2| 67|     F|       0|           0|            19|0.64|0.97|   0.8|         79|        103|      0|             122|              75|            121|              228|          2|       mild|BEBACOHORT|group2|               0|                2|      0|        0|        0|\n",
            "|  3| 88|     F|       0|           0|            13|0.83|0.86|  0.84|        101|        140|      1|             128|              72|            155|              198|          1|       mild|BEBACOHORT|group2|               1|                1|      1|        0|        0|\n",
            "|  4| 81|     F|       0|           0|            12|0.79|0.95|  0.87|         78|        123|      1|             131|              74|            146|              226|          2|       mild|BEBACOHORT|group2|               0|                0|      0|        0|        0|\n",
            "|  5| 79|     F|       0|           0|            14|0.84|0.93|  0.89|         96|        102|      0|             129|              80|            105|              189|          1|       mild|BEBACOHORT|group1|               0|                2|      1|        0|        0|\n",
            "+---+---+------+--------+------------+--------------+----+----+------+-----------+-----------+-------+----------------+----------------+---------------+-----------------+-----------+-----------+----------+------+----------------+-----------------+-------+---------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Cargar el modelo desde el archivo .pkl\n",
        "with open(\"modelo.pkl\", \"rb\") as f:\n",
        "    modelo = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "_Fo0Altc1qHa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, col\n",
        "\n",
        "# Asegurar codificación de 'gender' como numérico\n",
        "spark_df = spark_df.withColumn(\"gender\", when(col(\"gender\") == \"F\", 0).otherwise(1))\n"
      ],
      "metadata": {
        "id": "AyNcGaqQ2lBj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "import numpy as np\n",
        "\n",
        "# Columnas que espera el modelo\n",
        "feature_columns = ['age', 'gender', 'educationyears', 'glucose_min',\n",
        "                   'cholesterol_total', 'EF', 'PS', 'Global']\n",
        "\n",
        "# Función que aplica el modelo\n",
        "def predict_dementia(*cols):\n",
        "    X = np.array(cols).reshape(1, -1)\n",
        "    return float(modelo.predict(X)[0])  # devuelve 0 o 1\n",
        "\n",
        "# Crear la UDF\n",
        "predict_udf = udf(predict_dementia, DoubleType())\n"
      ],
      "metadata": {
        "id": "uJ-JuZWL2ohc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar nueva columna con predicción\n",
        "spark_df = spark_df.withColumn(\"prediction\", predict_udf(*[col(c) for c in feature_columns]))\n",
        "\n",
        "# Ver algunas predicciones\n",
        "spark_df.select(\"age\", \"gender\", \"prediction\").show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dffcDgC2rKU",
        "outputId": "f5a27e82-1c31-4580-bf9f-e602bea10a84"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----------+\n",
            "|age|gender|prediction|\n",
            "+---+------+----------+\n",
            "| 80|     0|       0.0|\n",
            "| 67|     0|       0.0|\n",
            "| 88|     0|       0.0|\n",
            "| 81|     0|       0.0|\n",
            "| 79|     0|       0.0|\n",
            "| 75|     0|       0.0|\n",
            "| 80|     0|       0.0|\n",
            "| 74|     0|       0.0|\n",
            "| 72|     0|       0.0|\n",
            "| 75|     1|       0.0|\n",
            "+---+------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}